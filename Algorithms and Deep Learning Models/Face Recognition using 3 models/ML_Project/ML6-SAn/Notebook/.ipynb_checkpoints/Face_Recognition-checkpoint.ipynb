{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8216f8-03a4-41ca-ae72-baabfdc8d6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Face Recognition in Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a835ce9e-5877-43d7-8dfd-473215f0d4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this Project used models - \n",
    "1) DeepFace\n",
    "2) FaceNet\n",
    "3) VGGNet\n",
    "4) FaceRecognition Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4653af2-0c9a-42e9-84fa-dbe8e53cd436",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "FaceRecognition library gives us higher Accuracy because no need of any models.\n",
    "Then Facenet and DeepFace almost gives similar Accuracy.\n",
    "VGGNet gives low Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3b1434-33c4-463e-8b1a-1d2da899781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Install following Packages -\n",
    "Numpy\n",
    "Keras\n",
    "deepface\n",
    "PIL\n",
    "tkinter\n",
    "cv2\n",
    "os\n",
    "tensorflow\n",
    "mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0971d19-93fc-4b9c-a693-8d00ad29992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "install the following and store in same working folder\n",
    "1) dlib-19.24.1-cp311-cp311-win_amd64.whl\n",
    "2) facenet_keras.h5\n",
    "3) vgg_face_weights.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b456d8-59b0-433b-9e02-1210abc6eb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "Create two folders namely imagesatted and imagebasics\n",
    "\n",
    "Store some images in imagesatted for recognition and dataset purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81582968-8d7b-4e35-9577-143698aa2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "Create Attendence.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1ab867-377c-41c6-90d8-372fd2d7a003",
   "metadata": {},
   "outputs": [],
   "source": [
    "Create the following python files.and also while running each separate file change their names into gui2.py and GUI.py.\n",
    "for ex. if you want to run DeepFace.py file then instead of AttendenceProject.py file change its name to DeepFace.py file into gui2.py file and GUI.py"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29c24f73-3541-4ac8-9811-f7341a28361c",
   "metadata": {},
   "source": [
    "#gui2.py\n",
    "\n",
    "from tkinter import *\n",
    "from PIL import ImageTk, Image\n",
    "import subprocess\n",
    "root = Tk()\n",
    "def hide_window():\n",
    " root.destroy()\n",
    "root.protocol(\"WM_DELETE_WINDOW\", hide_window) # Hide window when close button is clicked\n",
    "root.maxsize(width=800, height=600)\n",
    "root.title(\"Face Recognition System\")\n",
    "root.geometry(\"800x600\")\n",
    "#image = Image.open(\"C:/Users/Lenovo/Downloads/ML_PROJECT CUMMINS zip/ML_PROJECT CUMMINS/backbg.jpg\")\n",
    "#background_image = ImageTk.PhotoImage(image)\n",
    "#background_label = Label(root, image=background_image)\n",
    "#background_label.place(x=0, y=0, relwidth=1, relheight=1)\n",
    "\n",
    "image = Image.open(\"imagebasic/bg.jpg\") # Replace \"path_to_image_file.jpg\" with the actual path to your\n",
    "#image file\n",
    "image = image.resize((root.winfo_screenwidth(), root.winfo_screenheight()),)\n",
    "background_image = ImageTk.PhotoImage(image)\n",
    "background_label = Label(root, image=background_image)\n",
    "background_label.place(x=0, y=0, relwidth=1, relheight=1)\n",
    "\n",
    "UpdateDelay = 400\n",
    "s = 'Welcome Face Recognition System'\n",
    "s_index = 0\n",
    "def update():\n",
    " global s_index\n",
    " double = s + ' ' + s\n",
    " display = double[s_index:s_index+30]\n",
    " l.config(text=display)\n",
    " s_index += 1\n",
    " if s_index >= len(double) // 2:\n",
    "   s_index = 0\n",
    " root.after(UpdateDelay, update)\n",
    "l = Label(root, text='Welcome Face Recognition System', font=\"Calibri 18 bold\",\n",
    "bg='#CAEBF0')\n",
    "l.place(x=250, y=100)\n",
    "root.after(UpdateDelay, update)\n",
    "def open_new_window():\n",
    " root.destroy() # Close the first window\n",
    " subprocess.run([\"python\", \"gui.py\"]) # Open the new window\n",
    "jumpbtn = Button(root, text=\"Get Started\", padx=40, pady=20, command=open_new_window,bg='#CAEBF0', borderwidth=0, font=\"Times 14 bold\")\n",
    "jumpbtn.place(x=300, y=250)\n",
    "root.mainloop()\n",
    "\n",
    "\n",
    "from tkinter import *\n",
    "from tkinter import *\n",
    "from PIL import ImageTk, Image\n",
    "import subprocess\n",
    "# Create the Tkinter window\n",
    "window =Tk()\n",
    "window.title(\"Face Recognition\")\n",
    "window.geometry(\"800x600\")\n",
    "image = Image.open(\"imagebasic/bg.jpg\") # Replace \"path_to_image_file.jpg\" with the actual path to your\n",
    "#image file\n",
    "image = image.resize((window.winfo_screenwidth(), window.winfo_screenheight()),\n",
    "Image.ANTIALIAS)\n",
    "background_image = ImageTk.PhotoImage(image)\n",
    "background_label = Label(window, image=background_image)\n",
    "background_label.place(x=0, y=0, relwidth=1, relheight=1)\n",
    "# Create a button widget\n",
    "button = Button(window, padx=40, pady=20,text=\"For Recognition\",\n",
    "bg='#CAEBF0',command=lambda: subprocess.run([\"python\", \"program.py\"]))\n",
    "button .place(x=200,y=250)\n",
    "button1 =Button(window,padx=40, pady=20, text=\"For Attendance\", bg='#CAEBF0', command=lambda:\n",
    "subprocess.run([\"python\", \"DeepFace.py\"]))\n",
    "button1 .place(x=400,y=250)\n",
    "# Start the Tkinter event loop\n",
    "\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9a036a6-0cac-4165-929f-33e29472ce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GUI.py\n",
    "\n",
    "import tkinter as tk\n",
    "import subprocess\n",
    "\n",
    "\n",
    "def mark_attendance():\n",
    "    # Call the attendance.py file using subprocess\n",
    "    subprocess.Popen([\"python\", \"DeepFace.py\"])\n",
    "\n",
    "# Create the main application window\n",
    "root = tk.Tk()\n",
    "root.title(\"Attendance System\")\n",
    "\n",
    "# Create a button for marking attendance\n",
    "mark_button = tk.Button(root, text=\"Mark Attendance\", command=mark_attendance)\n",
    "mark_button.pack(pady=20)\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d509954-64ba-4b91-8a3b-adf9b308d2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AttendenceProject.py - FaceRecognition Library.\n",
    "\n",
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import tkinter as tk\n",
    "from PIL import ImageTk, Image\n",
    "\n",
    "def button():\n",
    "    path= 'imagesatted'\n",
    "    images=[]\n",
    "    classNames=[]\n",
    "    mylist=os.listdir(path)\n",
    "    print(mylist)\n",
    "    for cls in mylist:\n",
    "        curImg=cv2.imread(f'{path}/{cls}')\n",
    "        images.append(curImg)\n",
    "        classNames.append(os.path.splitext(cls)[0])\n",
    "    print(classNames)\n",
    "    def findEncodings(images):\n",
    "        encodeList =[]\n",
    "        for img in images:\n",
    "            img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "            encode=face_recognition.face_encodings(img)[0]\n",
    "            encodeList.append(encode)\n",
    "        return encodeList\n",
    "    def markAttendence(name):\n",
    "        with open('Attendance.csv', 'r+') as f:\n",
    "            myDataList = f.readlines()\n",
    "            print(myDataList)\n",
    "            nameList=[]\n",
    "            for line in myDataList:\n",
    "                entry= line.split(',')\n",
    "                nameList.append(entry[0])\n",
    "            if name not in nameList:\n",
    "                now = datetime.now()\n",
    "                dtString=now.strftime('%H:%M:%S')\n",
    "                f.writelines(f'\\n{name},{dtString}')\n",
    "\n",
    "    encodeListKnown = findEncodings(images)\n",
    "    print('Encoding complete')\n",
    "    cap=cv2.VideoCapture(0)\n",
    "    total_attempts = 0\n",
    "    correct_recognitions = 0\n",
    "    while True:\n",
    "        success, img=cap.read()\n",
    "        imgS = cv2.resize(img,(0,0),None,0.25,0.25)\n",
    "        imgS=cv2.cvtColor(imgS,cv2.COLOR_BGR2RGB)\n",
    "        facesCurFrame =face_recognition.face_locations(imgS)#TOP < BOTTOM< LEFT < RIGHT\n",
    "        encodesCurFrame=face_recognition.face_encodings(imgS,facesCurFrame)\n",
    "        #print(encodesCurFrame)\n",
    "        for encodeFace,faceLoc in zip(encodesCurFrame,facesCurFrame):\n",
    "            #print(encodeFace)\n",
    "            total_attempts += 1\n",
    "            print(faceLoc)\n",
    "            matches= face_recognition.compare_faces(encodeListKnown,encodeFace)\n",
    "            print(matches)\n",
    "            faceDis=face_recognition.face_distance(encodeListKnown,encodeFace)\n",
    "            #print(faceDis)\n",
    "            matchIndex=np.argmin(faceDis)\n",
    "            if matches[matchIndex]:\n",
    "                correct_recognitions += 1\n",
    "                name= classNames[matchIndex].upper()\n",
    "                accuracy = (correct_recognitions / total_attempts) * 100  # Calculate accuracy\n",
    "\n",
    "                y1,x2,y2,x1=faceLoc\n",
    "                y1,x2,y2,x1= y1*4,x2*4,y2*4,x1*4\n",
    "\n",
    "                print(name)\n",
    "                cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "                cv2.rectangle(img,(x1,y2-35),(x2,y2),(0,255,0),cv2.FILLED)\n",
    "                cv2.putText(img,f'{name} ({accuracy:.2f}%)',(x1+6,y2-6),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2) #2- thickness\n",
    "                markAttendence(name)\n",
    "                print(\"Attendance marked for\", name)\n",
    "\n",
    "\n",
    "        #shows live camera image\n",
    "        cv2.imshow('Webcam',img)\n",
    "        cv2.waitKey(1)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Create the main application window\n",
    "root = tk.Tk()\n",
    "root.title(\"Attendance System\")\n",
    "\n",
    "# Create a button for marking attendance\n",
    "def hide_window():\n",
    " root.destroy()\n",
    "root.protocol(\"WM_DELETE_WINDOW\", hide_window) # Hide window when close button is clicked\n",
    "root.maxsize(width=800, height=600)\n",
    "root.title(\"Face Recognition System\")\n",
    "root.geometry(\"800x600\")\n",
    "image = Image.open(\"imagebasic/bg.jpg\") # Replace \"path_to_image_file.jpg\" with the actual path to your\n",
    "#image file\n",
    "image = image.resize((root.winfo_screenwidth(), root.winfo_screenheight()),)\n",
    "background_image = ImageTk.PhotoImage(image)\n",
    "background_label = tk.Label(root, image=background_image)\n",
    "background_label.place(x=0, y=0, relwidth=1, relheight=1)\n",
    "l = tk.Label(root, text='Welcome Face Recognition System', font=\"Calibri 18 bold\", bg='#CAEBF0')\n",
    "l.place(x=250, y=100)\n",
    "mark_button = tk.Button(root, text=\"Mark Attendance\", command=button)\n",
    "mark_button.pack(pady=20)\n",
    "mark_button.place(x=350,y=250)\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e2f62c-ca88-4eda-8f49-b6def04bffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DeepFace.py\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from deepface import DeepFace\n",
    "\n",
    "# Path to your images folder\n",
    "path = 'imagesatted'\n",
    "images = []\n",
    "classNames = []\n",
    "\n",
    "# List the files in the images folder\n",
    "mylist = os.listdir(path)\n",
    "print(mylist)\n",
    "\n",
    "# Load images and extract class names\n",
    "for cls in mylist:\n",
    "    curImg = cv2.imread(os.path.join(path, cls))\n",
    "    if curImg is not None:\n",
    "        images.append(curImg)\n",
    "        classNames.append(os.path.splitext(cls)[0])\n",
    "print(classNames)\n",
    "\n",
    "# Function to find face encodings using DeepFace\n",
    "def findEncodings(images):\n",
    "    encodeList = []\n",
    "    for img in images:\n",
    "        try:\n",
    "            encodings = DeepFace.represent(img, model_name='VGG-Face', enforce_detection=False)\n",
    "            if encodings:\n",
    "                encodeList.append(encodings[0][\"embedding\"])\n",
    "        except Exception as e:\n",
    "            print(f\"Error encoding image: {e}\")\n",
    "    return encodeList\n",
    "\n",
    "# Function to mark attendance\n",
    "def markAttendance(name):\n",
    "    with open('Attendance.csv', 'r+') as f:\n",
    "        myDataList = f.readlines()\n",
    "        nameList = [line.split(',')[0] for line in myDataList]\n",
    "        if name not in nameList:\n",
    "            now = datetime.now()\n",
    "            dtString = now.strftime('%H:%M:%S')\n",
    "            f.writelines(f'\\n{name},{dtString}')\n",
    "\n",
    "# Find encodings for known faces\n",
    "encodeListKnown = findEncodings(images)\n",
    "print('Encoding complete')\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "total_attempts = 0\n",
    "correct_recognitions = 0\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    try:\n",
    "        # Detect faces in the current frame\n",
    "        facesCurFrame = DeepFace.extract_faces(imgS, detector_backend='mtcnn', enforce_detection=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Detection error: {e}\")\n",
    "        continue\n",
    "\n",
    "    for face in facesCurFrame:\n",
    "        faceLoc = face[\"facial_area\"]\n",
    "        faceImg = face[\"face\"]\n",
    "        try:\n",
    "            encodeFace = DeepFace.represent(faceImg, model_name='VGG-Face', enforce_detection=False)[0][\"embedding\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Representation error: {e}\")\n",
    "            continue\n",
    "\n",
    "        distances = np.linalg.norm(np.array(encodeListKnown) - encodeFace, axis=1)\n",
    "        matchIndex = np.argmin(distances)\n",
    "        total_attempts += 1  # Increment total attempts\n",
    "        if distances[matchIndex] < 0.6:  # Threshold for a valid recognition\n",
    "            correct_recognitions += 1  # Increment correct recognitions\n",
    "            name = classNames[matchIndex].upper()\n",
    "            y1, x2, y2, x1 = faceLoc[\"y\"], faceLoc[\"x\"] + faceLoc[\"w\"], faceLoc[\"y\"] + faceLoc[\"h\"], faceLoc[\"x\"]\n",
    "            y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.rectangle(img, (x1, y2 - 35), (x2, y2), (0, 255, 0), cv2.FILLED)\n",
    "            cv2.putText(img, name, (x1 + 6, y2 - 6), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)\n",
    "            markAttendance(name)\n",
    "            print(\"Attendance marked for\", name)\n",
    "        else:\n",
    "            print(f\"No match found. Distances: {distances}\")\n",
    "\n",
    "    # Show live camera image\n",
    "    cv2.imshow('Webcam', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Calculate and print accuracy\n",
    "if total_attempts > 0:\n",
    "    accuracy = (correct_recognitions / total_attempts) * 100\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "else:\n",
    "    print('No face recognition attempts made.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23840db3-00a6-4ef0-897a-e3d945d7f834",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FAceNet.py\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.models import load_model\n",
    "from mtcnn import MTCNN\n",
    "from numpy import asarray, expand_dims\n",
    "\n",
    "# Load the pre-trained FaceNet model\n",
    "model = load_model('facenet_keras.h5')\n",
    "\n",
    "# Function to preprocess the face for FaceNet model\n",
    "def preprocess_face(face):\n",
    "    face = cv2.resize(face, (160, 160))\n",
    "    face = face.astype('float32')\n",
    "    mean, std = face.mean(), face.std()\n",
    "    face = (face - mean) / std\n",
    "    face = expand_dims(face, axis=0)\n",
    "    return face\n",
    "\n",
    "# Function to get the face embedding using FaceNet\n",
    "def get_embedding(model, face):\n",
    "    face = preprocess_face(face)\n",
    "    embedding = model.predict(face)\n",
    "    return embedding[0]\n",
    "\n",
    "# Path to your images folder\n",
    "path = 'imagesatted'\n",
    "images = []\n",
    "classNames = []\n",
    "mylist = os.listdir(path)\n",
    "print(mylist)\n",
    "for cls in mylist:\n",
    "    curImg = cv2.imread(os.path.join(path, cls))\n",
    "    if curImg is not None:\n",
    "        images.append(curImg)\n",
    "        classNames.append(os.path.splitext(cls)[0])\n",
    "print(classNames)\n",
    "\n",
    "# Initialize MTCNN face detector\n",
    "detector = MTCNN()\n",
    "\n",
    "# Function to find face encodings for all images in the folder\n",
    "def findEncodings(images):\n",
    "    encodeList = []\n",
    "    for img in images:\n",
    "        results = detector.detect_faces(img)\n",
    "        if results:\n",
    "            x1, y1, width, height = results[0]['box']\n",
    "            x2, y2 = x1 + width, y1 + height\n",
    "            face = img[y1:y2, x1:x2]\n",
    "            encode = get_embedding(model, face)\n",
    "            encodeList.append(encode)\n",
    "    return encodeList\n",
    "\n",
    "# Function to mark attendance\n",
    "def markAttendance(name):\n",
    "    with open('Attendance.csv', 'r+') as f:\n",
    "        myDataList = f.readlines()\n",
    "        nameList = [line.split(',')[0] for line in myDataList]\n",
    "        if name not in nameList:\n",
    "            now = datetime.now()\n",
    "            dtString = now.strftime('%H:%M:%S')\n",
    "            f.writelines(f'\\n{name},{dtString}')\n",
    "\n",
    "# Find encodings for known faces\n",
    "encodeListKnown = findEncodings(images)\n",
    "print('Encoding complete')\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "total_attempts = 0\n",
    "correct_recognitions = 0\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success or img is None:\n",
    "        print(\"Failed to capture image from camera.\")\n",
    "        continue\n",
    "\n",
    "    imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    facesCurFrame = detector.detect_faces(imgS)\n",
    "    encodesCurFrame = []\n",
    "\n",
    "    for result in facesCurFrame:\n",
    "        x1, y1, width, height = result['box']\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        face = imgS[y1:y2, x1:x2]\n",
    "        encode = get_embedding(model, face)\n",
    "        encodesCurFrame.append((encode, (x1, y1, x2, y2)))\n",
    "\n",
    "    for encodeFace, faceLoc in encodesCurFrame:\n",
    "        total_attempts += 1\n",
    "        distances = np.linalg.norm(np.array(encodeListKnown) - encodeFace, axis=1)\n",
    "        matchIndex = np.argmin(distances)\n",
    "        if distances[matchIndex] < 0.6:  # Threshold for a valid recognition\n",
    "            correct_recognitions += 1\n",
    "            name = classNames[matchIndex].upper()\n",
    "            y1, x2, y2, x1 = faceLoc\n",
    "            y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.rectangle(img, (x1, y2 - 35), (x2, y2), (0, 255, 0), cv2.FILLED)\n",
    "\n",
    "            # Calculate accuracy and display it with the name\n",
    "            accuracy = (correct_recognitions / total_attempts) * 100 if total_attempts > 0 else 0\n",
    "            cv2.putText(img, f\"{name} {accuracy:.2f}%\", (x1 + 6, y2 - 6), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)\n",
    "            markAttendance(name)\n",
    "            print(\"Attendance marked for\", name)\n",
    "\n",
    "    # Show live camera image\n",
    "    cv2.imshow('Webcam', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Calculate and print final accuracy\n",
    "if total_attempts > 0:\n",
    "    accuracy = (correct_recognitions / total_attempts) * 100\n",
    "    print(f'Final Accuracy: {accuracy:.2f}%')\n",
    "else:\n",
    "    print('No face recognition attempts made.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e9fe87-efbc-496f-98b5-91c96bd55b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGGNet.py\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from deepface import DeepFace\n",
    "\n",
    "# Path to your images folder\n",
    "path = 'imagesatted'\n",
    "images = []\n",
    "classNames = []\n",
    "\n",
    "# List the files in the images folder\n",
    "mylist = os.listdir(path)\n",
    "print(mylist)\n",
    "\n",
    "# Load images and extract class names\n",
    "for cls in mylist:\n",
    "    curImg = cv2.imread(os.path.join(path, cls))\n",
    "    if curImg is not None:\n",
    "        images.append(curImg)\n",
    "        classNames.append(os.path.splitext(cls)[0])\n",
    "print(classNames)\n",
    "\n",
    "# Function to find face encodings using DeepFace\n",
    "def findEncodings(images):\n",
    "    encodeList = []\n",
    "    for img in images:\n",
    "        try:\n",
    "            encodings = DeepFace.represent(img, model_name='VGG-Face')\n",
    "            if encodings:\n",
    "                encodeList.append(encodings[0][\"embedding\"])\n",
    "        except Exception as e:\n",
    "            print(f\"Error encoding image: {e}\")\n",
    "    return encodeList\n",
    "\n",
    "# Function to mark attendance\n",
    "def markAttendance(name):\n",
    "    with open('Attendance.csv', 'r+') as f:\n",
    "        myDataList = f.readlines()\n",
    "        nameList = [line.split(',')[0] for line in myDataList]\n",
    "        if name not in nameList:\n",
    "            now = datetime.now()\n",
    "            dtString = now.strftime('%H:%M:%S')\n",
    "            f.writelines(f'\\n{name},{dtString}')\n",
    "\n",
    "# Find encodings for known faces\n",
    "encodeListKnown = findEncodings(images)\n",
    "print('Encoding complete')\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "total_attempts = 0\n",
    "correct_recognitions = 0\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    try:\n",
    "        # Detect faces in the current frame\n",
    "        facesCurFrame = DeepFace.extract_faces(imgS, detector_backend='mtcnn', enforce_detection=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Detection error: {e}\")\n",
    "        continue\n",
    "\n",
    "    for face in facesCurFrame:\n",
    "        faceLoc = face[\"facial_area\"]\n",
    "        faceImg = face[\"face\"]\n",
    "        try:\n",
    "            encodeFace = DeepFace.represent(faceImg, model_name='VGG-Face', enforce_detection=False)[0][\"embedding\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Representation error: {e}\")\n",
    "            continue\n",
    "\n",
    "        distances = np.linalg.norm(np.array(encodeListKnown) - encodeFace, axis=1)\n",
    "        matchIndex = np.argmin(distances)\n",
    "        total_attempts += 1  # Increment total attempts\n",
    "        if distances[matchIndex] < 0.6:  # Threshold for a valid recognition\n",
    "            correct_recognitions += 1  # Increment correct recognitions\n",
    "            name = classNames[matchIndex].upper()\n",
    "            y1, x2, y2, x1 = faceLoc[\"y\"], faceLoc[\"x\"] + faceLoc[\"w\"], faceLoc[\"y\"] + faceLoc[\"h\"], faceLoc[\"x\"]\n",
    "            y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.rectangle(img, (x1, y2 - 35), (x2, y2), (0, 255, 0), cv2.FILLED)\n",
    "\n",
    "            # Calculate accuracy and display it with the name\n",
    "            accuracy = (correct_recognitions / total_attempts) * 100 if total_attempts > 0 else 0\n",
    "            cv2.putText(img, f\"{name} {accuracy:.2f}%\", (x1 + 6, y2 - 6), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)\n",
    "            markAttendance(name)\n",
    "            print(\"Attendance marked for\", name)\n",
    "        else:\n",
    "            print(f\"No match found. Distances: {distances}\")\n",
    "\n",
    "    # Show live camera image\n",
    "    cv2.imshow('Webcam', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Calculate and print accuracy\n",
    "if total_attempts > 0:\n",
    "    accuracy = (correct_recognitions / total_attempts) * 100\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "else:\n",
    "    print('No face recognition attempts made.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b8ff63-d581-4f47-9776-9145602c4b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "Run gui2.py file and done you can recognize image."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
